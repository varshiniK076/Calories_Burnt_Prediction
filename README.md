# ğŸ”¥ğŸƒ Calories_Burnt_Prediction

## ğŸ“ Project Overview

The **Calories Burnt Prediction System** is a machine learning solution designed to estimate the energy expenditure of individuals based on their exercise metrics and physiological data. By analyzing factors such as heart rate, duration of exercise, body temperature, and demographics, the system provides accurate calorie burn estimates.

This project covers the complete machine learning pipeline, from data ingestion, random sample imputation, and variable transformation to feature selection, model training, and deployment through a **Flask web application**.

## ğŸ¯ Main Goal
The main goal of the **Calories Burnt Prediction System** is to **assist fitness enthusiasts and healthcare providers** by providing a reliable tool to track calorie expenditure, helping users manage their fitness goals and monitor workout intensity effectively.

## ğŸ“ Dataset Description
The project utilizes data merging two sources: exercise data and calorie data, joined by a unique user identifier. It captures physical performance metrics and physiological stats.

| Feature | Description |
| :--- | :--- |
| **User_ID** | Unique identifier for each user |
| **Gender** | Gender of the user (Male / Female) |
| **Age** | Age of the user in years |
| **Height** | Height of the user in centimeters |
| **Weight** | Weight of the user in kilograms |
| **Duration** | Duration of the exercise in minutes |
| **Heart_Rate** | Heart rate in beats per minute (bpm) during exercise |
| **Body_Temp** | Body temperature in Celsius during exercise |
| **Calories** | (Target) Total calories burned during the session |

### ğŸ·ï¸ Dataset Categories
- **Target Variable:** `Calories` (Numerical)
- **Demographics:** `Gender`, `Age`, `Height`, `Weight`
- **Physiological/Performance:** `Duration`, `Heart_Rate`, `Body_Temp`

---

## ğŸ—‚ï¸ Project Structure

```text
Calories_Burnt_Prediction/
â”‚
â”œâ”€ data/
â”‚   â”œâ”€ exercise.csv           # Feature data
â”‚   â””â”€ calories.csv           # Target data
â”‚
â”œâ”€ app.py                     # Flask web application entry point
â”œâ”€ main.py                    # Main script to run the ML pipeline
â”œâ”€ random_sample_imputataion.py # Handling missing values
â”œâ”€ variable_transformation.py # Log transform & Quantile capping
â”œâ”€ feature_selection.py       # Variance threshold & Correlation checks
â”œâ”€ Scaling.py                 # Feature scaling (StandardScaler)
â”œâ”€ model_training.py          # Linear Regression training script
â”œâ”€ log_code.py                # Logging configuration
â”‚
â”œâ”€ models/
â”‚   â”œâ”€ calories.pkl           # Trained Linear Regression model
â”‚   â”œâ”€ scaling.pkl            # Saved StandardScaler object
â”‚
â”œâ”€ templates/
â”‚   â””â”€ index.html             # Frontend HTML for Flask app
â”‚
â”œâ”€ plot_path/                 # Saved KDE and Boxplots for analysis
â”‚
â”œâ”€ requirements.txt           # Required Python packages
â””â”€ README.md                  # Project documentation


```
# ğŸ”„ ML - Pipeline

The system uses a modular machine learning pipeline to ensure data quality and model accuracy. It handles missing values using random sampling, normalizes skewed data, encodes categorical variables, and scales features before training a regression model.

---

### ğŸ“Š Data Visualization
- **Library:** Matplotlib & Seaborn  
- **Techniques used:** KDE Plots (Kernel Density Estimation), Boxplots  
- **Purpose:** Visualize data distribution and detect outliers before and after variable transformation  

---

### ğŸ› ï¸ Feature Engineering

#### 1ï¸âƒ£ Handling Missing Values
- **Script:** `random_sample_imputation.py`  
- **Technique:** Random Sample Imputation  
- **Method:** Missing values in training and testing sets are filled by sampling random values from observed data  
- **Reason:** Preserves original variance and distribution better than mean/median imputation  

#### 2ï¸âƒ£ Variable Transformation
- **Script:** `variable_transformation.py`  
- **Techniques:**  
  - Log Transformation: `np.log1p` to numeric features to reduce skewness  
  - Quantile Capping: Outliers capped between 1st (0.01) and 99th (0.99) percentiles based on training data  
- **Reason:** Normalizes data distribution for linear regression  

#### 3ï¸âƒ£ Categorical Encoding
- **Script:** `main.py`  
- **Technique:** One-Hot Encoding  
- **Target:** `Gender` column  
- **Method:** Converts Gender into numeric representation (dropping the first category to avoid multicollinearity)  

#### 4ï¸âƒ£ Feature Selection (Hypothesis Testing)
- **Script:** `feature_selection.py`  
- **Techniques:**  
  - Constant/Quasi-Constant Removal: Removes features with 0 variance  
  - Pearson Correlation: Checks correlation between features and target  
- **Outcome:** Only statistically significant features contribute to the model  

---

### âš–ï¸ Feature Scaling
- **Script:** `Scaling.py`  
- **Technique:** StandardScaler  
- **Method:** Standardizes features by removing the mean and scaling to unit variance  
- **Reason:** Ensures features with larger magnitudes do not dominate the Linear Regression objective  

---

### ğŸ§  Model Training
- **Model:** Linear Regression (`sklearn.linear_model.LinearRegression`)  
- **Workflow:**  
  1. Data split into Train/Test sets (80/20)  
  2. Model trained on scaled data  
  3. Model serialized (`calories.pkl`) for deployment  

---

### ğŸŒ Deployment (Flask Web App)
- **Script:** `app.py`  
- **Frontend:** HTML form taking inputs for Age, Height, Weight, Duration, Heart Rate, Body Temp, and Gender  
- **Backend:**  
  - Loads `calories.pkl` and `scaling.pkl`  
  - Preprocesses user input (Gender â†’ numeric, scales data)  
  - Returns predicted calorie count  

---

### ğŸ“¦ Install Required Packages
```bash
pip install -r requirements.txt
```

## **ğŸš€ Run the Project**
> ```
> python main.py
> python app.py
> ```
---


## **ğŸ‘¤ Author**
 ```
 Varadhana Varshini Kolipakula
 Machine Learning & Data Science Enthusiast
 ```

---
